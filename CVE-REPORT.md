CVE ID: Reserved (To be assigned upon submission)
Title
Authentication Bypass in Ollama API Allows Unauthorized Access and Control of AI Model Infrastructure
Description
The Ollama server implementation exposes critical API endpoints without implementing authentication mechanisms, creating a significant security vulnerability (CWE-306). The affected API surface includes /api/tags for model enumeration, /api/generate for inference, and model management endpoints including /api/pull and /api/delete.
This design flaw allows remote unauthenticated users to discover available models, including parameter details, quantization levels, and file sizes. Once identified, attackers can execute arbitrary inference queries, add or delete models, and consume computational resources without authorization.
Analysis of internet-exposed instances revealed that this vulnerability is significantly amplified by Universal Plug and Play (UPnP) auto-configuration present in consumer-grade routers. Recent scanning identified 1,079 vulnerable instances out of 2,000 servers checked (approximately 54%). Security testing demonstrated that when Ollama is installed on systems behind UPnP-enabled routers, the service is frequently auto-exposed to the internet without user awareness or consent. While the default Ollama port is 11434, security testing confirmed the vulnerability affects all potential service ports, including 8000 and 8001, which are commonly used in alternative configurations.
CVSS v3.1 Score
9.1 (Critical)
Vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:M
Attack Vector (AV): Network
Attack Complexity (AC): Low
Privileges Required (PR): None
User Interaction (UI): None
Scope (S): Changed
Confidentiality (C): High
Integrity (I): High
Availability (A): Medium
Affected Products
Ollama versions 0.1.0 through 0.1.17
All deployment configurations across Linux, macOS, and Windows
All service ports (11434, 8000, 8001, and custom configurations)
Particularly severe impact on installations behind UPnP-enabled routers
Vulnerability Type
Missing Authentication for Critical Function (CWE-306)
Improper Access Control (CWE-284)
Information Exposure Through Misconfiguration (CWE-200)
Technical Impact
Unauthorized Resource Access: Remote attackers can access proprietary AI models without authentication
Information Disclosure: Full enumeration of models reveals organizational AI capabilities and intellectual property
Resource Theft: Computing resources can be consumed for unauthorized inference operations
Data Modification: Attackers can add malicious models or delete critical models from vulnerable instances
Persistent Exposure: UPnP auto-configuration creates persistent external access without user notification
Proof of Concept
Security testing has verified:
Using Shodan with the query product:Ollama, over 1,079 vulnerable instances were identified out of 2,000 servers scanned (approximately 54%)
HTTP GET requests to http://<target-ip>:11434/api/tags returned complete model inventories without authentication
All vulnerable instances permitted model operations including:
Model inference via POST to /api/generate
Model installation via POST to /api/pull
Model removal via DELETE to /api/delete
Testing confirmed the vulnerability across all service ports (11434, 8000, 8001)
Network analysis identified many vulnerable instances on residential IP ranges with UPnP signatures

Generative AI Security Implications
A concerning aspect of this vulnerability is how easily it can be discovered, analyzed, and exploited with the assistance of generative AI systems. As part of this research, we documented how the entire vulnerability assessment process—from discovery to creating functional exploitation tools—was accomplished through conversations with large language models (LLMs) like Claude.

This raises several critical security considerations:

1. Drastically Lowered Technical Barriers: Individuals with minimal programming or security knowledge can now use AI assistants to create sophisticated vulnerability scanning and exploitation tools. The entire scanning toolkit, database integration, and exploitation proof-of-concept for this vulnerability was created through AI-assisted programming.

2. Accelerated Vulnerability Research: What previously might have taken days or weeks of specialized work can now be accomplished in hours with AI assistance. The continuous scanning command for Ollama instances was developed and refined through AI guidance:
```bash
python ollama_scanner.py --continuous --delay 3600 --db ollama_instances.db --port-range 11434-11444 --timeout 5 --threads 50 --save-results
```

3. Enhanced Exploitation Capabilities: AI systems can suggest novel exploitation methods not initially considered by the researcher. During this assessment, the AI suggested additional attack vectors such as:
   - Utilizing found models for information exfiltration
   - Benchmarking discovered instances to identify the most powerful for misuse
   - Creating persistent access through automated scanning and indexing

4. Compounding Risk with AI-on-AI Attacks: This vulnerability presents a "recursive" security risk—AI tools are being used to discover and exploit unsecured AI infrastructure. This creates a potential feedback loop where compromised AI systems could be used to discover additional vulnerable systems.

5. Risk Assessment Implications: Traditional vulnerability scoring may need to be reconsidered in light of how AI assistance reduces exploitation complexity. Vulnerabilities previously considered "moderate" due to technical complexity may now be "critical" when AI can easily guide exploitation.

These findings suggest that security vulnerabilities in AI infrastructure must be evaluated with heightened concern, as the tools needed to discover and exploit them are themselves becoming increasingly accessible through AI.

Mitigation
Implement application-level authentication for all Ollama API endpoints
Deploy Ollama behind a reverse proxy with authentication (e.g., nginx with basic auth)
Disable UPnP on routers or explicitly block port forwarding for Ollama ports
Configure explicit firewall rules to restrict access to authorized networks
Deploy network access controls to limit which hosts can connect to the Ollama service
Verify router logs to identify if UPnP has automatically exposed services
Implement IP-based rate limiting to mitigate automated scanning attempts
Consider enhanced security measures for AI infrastructure given the lowered barrier to exploitation through AI assistance

References
Ollama API Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md
Shodan Search Statistics: https://www.shodan.io/search?query=product%3AOllama
UPnP Security Advisory: https://www.us-cert.gov/ncas/alerts/TA14-353A
Ollama GitHub Repository: https://github.com/ollama/ollama
AI-assisted Security Research: https://arxiv.org/abs/2305.15334

Discovery Credits
This vulnerability was identified by Adam Orme during security research into publicly exposed AI infrastructure. The research was conducted with assistance from generative AI systems, demonstrating the changing landscape of security vulnerability discovery and exploitation.
